# Apache Spark
</br>
In this project I use Apache Spark with SCALA programing language instead of PYTHON.</br>
I chose Scala because Spark is written in Scala, good fit for distributed processing,</br>
gives you fast performance</br>
Spark provides cluster (consisting of individual computers) framework for large scale data   </br>
processing  through its stack (data storage, resource management like cubernetes, spark core  </br>
API supporting spark libraries like spark sql, spark MLlib etc.).</br>
</br>
In this project I am focusing how to work with Spark including:
                               - Creating a spark session
                               - Reading data from a computer
                               - Explore the dataset
                               - Working with DataFrames and DataSets
                               - Spark SQL
                               - RDD (Resilient Ditributed Dataset)
