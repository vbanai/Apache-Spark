# Apache Spark
</br>
In this project I use Apache Spark with SCALA programing language instead of PYTHON.</br>
I chose Scala because Spark is written in Scala, good fit for distributed processing,</br>
gives you fast performance</br>
Spark provides cluster (consisting of individual computers) framework for large scale data   </br>
processing  through its stack (data storage, resource management like cubernetes, spark core  </br>
API supporting spark libraries like spark sql, spark MLlib etc.).</br>
</br>
In this project I am focusing how to work with Spark including:</br>
                               - Creating a spark session</br>
                               - Reading data from a computer</br>
                               - Explore the dataset</br>
                               - Working with DataFrames and DataSets</br>
                               - Spark SQL</br>
                               - RDD (Resilient Ditributed Dataset)</br>
